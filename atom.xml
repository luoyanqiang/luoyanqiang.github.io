<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Developer</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-06-12T11:55:43.865Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Luo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>性能测试指标</title>
    <link href="http://yoursite.com/2019/06/08/%E7%BD%91%E7%AB%99%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87%EF%BC%88QPS%EF%BC%8CTPS%EF%BC%8C%E5%90%9E%E5%90%90%E9%87%8F%EF%BC%8C%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4%EF%BC%89%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2019/06/08/网站性能测试指标（QPS，TPS，吞吐量，响应时间）详解/</id>
    <published>2019-06-08T14:51:41.000Z</published>
    <updated>2019-06-12T11:55:43.865Z</updated>
    
    <content type="html"><![CDATA[<p>常用的网站性能测试指标有：吞吐量、并发数、响应时间、性能计数器等。</p><h2 id="并发数"><a href="#并发数" class="headerlink" title="并发数"></a>并发数</h2><p>并发数是指系统同时能处理的请求数量，这个也是反应了系统的负载能力。</p><h2 id="响应时间"><a href="#响应时间" class="headerlink" title="响应时间"></a>响应时间</h2><p>响应时间是一个系统最重要的指标之一，它的数值大小直接反应了系统的快慢。响应时间是指执行一个请求从开始到最后收到响应数据所花费的总体时间。</p><h2 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h2><p>吞吐量是指单位时间内系统能处理的请求数量，体现系统处理请求的能力，这是目前最常用的性能测试指标。</p><p>QPS（每秒查询数）、TPS（每秒事务数）是吞吐量的常用量化指标，另外还有HPS（每秒HTTP请求数）。</p><p>跟吞吐量有关的几个重要是：并发数、响应时间。</p><p>QPS（TPS），并发数、响应时间它们三者之间的关系是：</p><p>QPS（TPS）= 并发数/平均响应时间</p><h2 id="性能计数器"><a href="#性能计数器" class="headerlink" title="性能计数器"></a>性能计数器</h2><p>性能计数器是描述服务器或操作系统性能的一些数据指标，如使用内存数、进程时间，在性能测试中发挥着“监控和分析”的作用，尤其是在分析统统可扩展性、进行新能瓶颈定位时有着非常关键的作用。</p><p>Linux中可以使用top或者uptime命令看到当前系统的负载及资源利用率情况。</p><p>资源利用率：指系统各种资源的使用情况，如cpu占用率为68%，内存占用率为55%，一般使用“资源实际使用/总的资源可用量”形成资源利用率。</p><p>所以，一个网站优化的目的即是，最大限度的利用好服务器硬件资源提升资源利用率，减少用户请求的响应时间，提高系统吞吐量，提高系统并发数。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;常用的网站性能测试指标有：吞吐量、并发数、响应时间、性能计数器等。&lt;/p&gt;
&lt;h2 id=&quot;并发数&quot;&gt;&lt;a href=&quot;#并发数&quot; class=&quot;headerlink&quot; title=&quot;并发数&quot;&gt;&lt;/a&gt;并发数&lt;/h2&gt;&lt;p&gt;并发数是指系统同时能处理的请求数量，这个也是反应了
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>线程池</title>
    <link href="http://yoursite.com/2019/05/24/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    <id>http://yoursite.com/2019/05/24/线程池/</id>
    <published>2019-05-24T12:02:10.000Z</published>
    <updated>2019-06-12T11:43:59.558Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h1><h2 id="线程池的好处"><a href="#线程池的好处" class="headerlink" title="线程池的好处"></a>线程池的好处</h2><ol><li>降低资源消耗： 通过重复利用已创建的线程降低线程创建和销毁造成的消耗</li><li>提高响应速度： 当任务到达时，任务可以不用等到线程创建就能立即执行</li><li>提高线程的可管理性： 使用线程性可以统一分配、调优和监控</li></ol><h2 id="线程数量"><a href="#线程数量" class="headerlink" title="线程数量"></a>线程数量</h2><ol><li>CPU密集型任务应配置尽可能小的线程，如配置N(CPU) + 1 个线程的线程池；</li><li>IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如2 * N（CPU)</li></ol><h2 id="使用线程池"><a href="#使用线程池" class="headerlink" title="使用线程池"></a>使用线程池</h2><ol><li><p>创建<br>new ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit,                          BlockingQueue<runnable> workQueue)</runnable></p></li><li><p>提交任务</p></li></ol><ul><li>execute()</li><li>submit()</li></ul><ul><li>execute 方法用于提交不需要返回值的任务</li><li>submit 方法用于提交需要返回值的任务。 线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，future.get()可以获取返回值</li></ul><ol start="3"><li>关闭线程池</li></ol><ul><li>shutdown()</li><li>shutdownNow()</li></ul><p>通常用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法</p><h1 id="Executor框架"><a href="#Executor框架" class="headerlink" title="Executor框架"></a>Executor框架</h1><ul><li>任务： 包括被执行任务需要实现的接口： <strong>Runnable接口</strong>或<strong>Callable接口</strong></li><li>任务的执行： 包括任务执行机制的核心接口Executor, 以及继承自Executor的ExecutorService接口。 <strong>ThreadPoolExecutor</strong> 和 <strong>ScheduledThreadPoolExecutor</strong> 两个关键类实现了ExecutorService接口</li><li>异步计算的结果： 包括接口Future和实现Future接口的FutureTask类</li></ul><h2 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h2><ul><li>FixedThreadPool:   适用于需要限制当前线程数量的应用场景</li><li>SingleThreadExecutor： 适用于需要保证顺序地执行各个任务</li><li>CachedThreadPool： 是大小无界的线程池，适用于执行很多的短期异步任务的小程序</li></ul><blockquote><blockquote><p>通用使用工厂类Executors来创建。</p></blockquote></blockquote><h2 id="ScheduledThreadPoolExecutor"><a href="#ScheduledThreadPoolExecutor" class="headerlink" title="ScheduledThreadPoolExecutor"></a>ScheduledThreadPoolExecutor</h2><ul><li>ScheduledThreadPoolExecutor</li><li>SingleThreadScheduledExecutor</li></ul><h2 id="Runnable接口-和-Callable接口"><a href="#Runnable接口-和-Callable接口" class="headerlink" title="Runnable接口 和 Callable接口"></a>Runnable接口 和 Callable接口</h2><blockquote><blockquote><p>Runnable不会返回结果，Callable可以返回结果<br>工具类Executors可以把Runnable对象封装为一个Callable对象，Executors.callable(Runnable task)</p></blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线程池&quot;&gt;&lt;a href=&quot;#线程池&quot; class=&quot;headerlink&quot; title=&quot;线程池&quot;&gt;&lt;/a&gt;线程池&lt;/h1&gt;&lt;h2 id=&quot;线程池的好处&quot;&gt;&lt;a href=&quot;#线程池的好处&quot; class=&quot;headerlink&quot; title=&quot;线程池的好处&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>7个性能指标</title>
    <link href="http://yoursite.com/2019/04/04/Java%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E9%A1%BB%E6%B8%85%E6%A5%9A%E7%9A%84%207%20%E4%B8%AA%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/"/>
    <id>http://yoursite.com/2019/04/04/Java 程序员必须清楚的 7 个性能指标/</id>
    <published>2019-04-04T12:08:40.000Z</published>
    <updated>2019-06-12T11:53:45.247Z</updated>
    
    <content type="html"><![CDATA[<p>本文中，小编搜集了7个最有影响的衡量标注，让你可以不依赖日志文件来了解应用程序。现在，让我们看看这些性能指标，并了解如何查看并收集它们：</p><h2 id="响应时间和吞吐量"><a href="#响应时间和吞吐量" class="headerlink" title="响应时间和吞吐量"></a>响应时间和吞吐量</h2><p>根据应用程序的响应时间可以知道程序完成传输数据所用的时间。也可以从HTTP请求级别，或者成为数据库级别来看。对那些缓慢的查询你需要做一些优化来缩短时间。吞吐量是另一个角度衡量传输数据的指标，是指单位时间内系统处理的客户请求的数量。</p><p>我们可以使用APMs（例如New Relic或AppDynamics）来衡量这些指标。使用这些工具，你可以在主报告仪表板中将平均响应时间与昨天的甚至上周的直接进行对比。这有助于我们观察新的部署是否会影响到我们的应用程序。你可以看到网络传输的百分比，测量HTTP完成请求需要多长时间。你也可以看看这篇：网站性能测试指标（QPS，TPS，吞吐量，响应时间）详解。</p><blockquote><blockquote><p>推荐工具：</p></blockquote></blockquote><ul><li>AppDynamics</li><li>New Relic</li><li>Ruxit</li></ul><p>New Relic报告：Web传输百分比和吞吐量</p><h2 id="平均负载"><a href="#平均负载" class="headerlink" title="平均负载"></a>平均负载</h2><p>第二个应用广泛的指标是平均负载。我们习惯上会把平均负载分为这三步测量，分别是第5分钟、第15分钟和最后1分钟。要保证数量低于机器的内核数。一旦超过内核数，机器就会运行在压力状态下。</p><p>除了简单测量CPU使用率，还需要关注每个内核的队列中有多少进程。在内核使用率都是100%的情况下，队列中只有1个任务和有6个任务有很大不同。因此，平均负载不能只考虑CPU使用率。</p><blockquote><blockquote><p>推荐工具：</p></blockquote></blockquote><ul><li>htop</li></ul><h2 id="错误率"><a href="#错误率" class="headerlink" title="错误率"></a>错误率</h2><p>大多数开发人员判断错误率是根据HTTP传输总失败百分比。但是他们忽略了一个更深层的东西：特定传输的错误率。这直接影响到您应用程序的运行状况。这可以显示出代码方法的错误以及错误或异常出现的次数。</p><p>但单纯的错误率数据对我们没有多大帮助。最重要的是我们要找到它们的根源并解决问题。随着Takipi的运行，我们要在日志文件中需找线索。你可以找到所有关于服务器状态的信息，包括堆栈跟踪、源代码和变量值。</p><blockquote><blockquote><p>推荐工具：</p></blockquote></blockquote><ul><li>Takipi</li></ul><h2 id="GC率和暂停时间"><a href="#GC率和暂停时间" class="headerlink" title="GC率和暂停时间"></a>GC率和暂停时间</h2><p>异常行为垃圾收集器应用程序的吞吐量和响应时间采取深潜的主要原因之一。了解GC暂停频率和持续时间的关键是分析GC日志文件。要分析它们，你需要收集GC日志和JVM参数。你要注意观察不同指标之间的数据是如何相互影响的。</p><blockquote><blockquote><p>推荐工具：</p></blockquote></blockquote><ul><li>jClarity Censum</li><li>GCViewer</li></ul><h2 id="业务指标"><a href="#业务指标" class="headerlink" title="业务指标"></a>业务指标</h2><p>应用程序的性能不完全取决于响应时间和错误率。业务指标也是一方面，例如收益、用户数。</p><blockquote><blockquote><p>推荐工具：</p></blockquote></blockquote><ul><li>Grafana</li><li>The ELK stack</li><li>Datadog</li><li>Librato</li></ul><h2 id="正常运行时间和服务运行状态"><a href="#正常运行时间和服务运行状态" class="headerlink" title="正常运行时间和服务运行状态"></a>正常运行时间和服务运行状态</h2><p>这一指标奠定了整个应用程序性能的基础。不仅可以当做一个提醒指标，也可以让你定义一段时间内的SKA。我们可以使用Pingdom的servlet功能进行运行状态检查。我们可以查到应用程序的所有传输，包括数据库和S3。你也可以看看这篇：SLA服务可用性4个9是什么意思？怎么达到？</p><blockquote><blockquote><p>推荐工具：</p></blockquote></blockquote><ul><li>Pingdom</li></ul><h2 id="日志大小"><a href="#日志大小" class="headerlink" title="日志大小"></a>日志大小</h2><p>日志有一个缺点，它是一直在增加的。当您的服务器启动塞满了垃圾，一切都慢下来。因此，我们需要密切的关注日志大小。</p><p>目前通常的解决办法是使用logstash划分使用日志，并将它们发送并存储在Splunk、ELK或其他的日志管理工具中。</p><blockquote><blockquote><p>推荐工具：</p></blockquote></blockquote><ul><li>Splunk</li><li>Sumo Logic</li><li>Loggly</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文中，小编搜集了7个最有影响的衡量标注，让你可以不依赖日志文件来了解应用程序。现在，让我们看看这些性能指标，并了解如何查看并收集它们：&lt;/p&gt;
&lt;h2 id=&quot;响应时间和吞吐量&quot;&gt;&lt;a href=&quot;#响应时间和吞吐量&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch &amp; MySQL</title>
    <link href="http://yoursite.com/2019/02/11/ElasticSearch%20&amp;%20Mysql/"/>
    <id>http://yoursite.com/2019/02/11/ElasticSearch &amp; Mysql/</id>
    <published>2019-02-11T14:23:15.000Z</published>
    <updated>2019-06-12T11:54:32.412Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Elasticsearch-amp-MySQL"><a href="#Elasticsearch-amp-MySQL" class="headerlink" title="Elasticsearch &amp; MySQL"></a>Elasticsearch &amp; MySQL</h1><p>Elasticsearch is used as an open-source, distributed search engine. MySQL is an open-source, relational database management system.</p><p>There are serval ways of pushing existing relational data to Elasticsearch.</p><h2 id="Logstash-JDBC-input-plugin"><a href="#Logstash-JDBC-input-plugin" class="headerlink" title="Logstash JDBC input plugin"></a>Logstash JDBC input plugin</h2><p>This time I’ll show you pushing existing relational data to Elasticsearch using Logstash JDBC input plugin. This plugin has been created as a way to ingest data in any database with a JDBC interface into Logstash. </p><p>Firstly let’s create a config file to instruct the Logstash, the way data injection should happen. </p><p>The example configuration named “logstash-config.conf” as followed.</p><pre><code>input {  jdbc {    jdbc_driver_library =&gt; &quot;/usr/local/src/library/mysql-connector-java-5.1.46.jar&quot;    jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;    jdbc_connection_string =&gt; &quot;jdbc:mysql://192.168.0.112:3306/sharing_space&quot;    jdbc_user =&gt; &quot;root&quot;    jdbc_password =&gt; &quot;Hepai2018&quot;    schedule =&gt; &quot;*/5 * * * *&quot;    statement =&gt; &quot;select s.*, area.`name` as area_name, district.`name` as district_name, top_industry.industry_name as top_industry_name, sub_industry.industry_name as sub_industry_name from share_space s LEFT JOIN share_area area on s.area_id = area.area_id left join share_district district on s.district_id = district.district_id left join share_industry top_industry on s.industry_id = top_industry.industry_id left join share_industry sub_industry on s.sub_industry_id = sub_industry.industry_id where s.update_time&gt;:sql_last_value order by s.space_id&quot;    use_column_value =&gt; true    tracking_column =&gt; update_time    tracking_column_type =&gt; &quot;timestamp&quot;    jdbc_paging_enabled =&gt; true    jdbc_page_size =&gt; 500    tags =&gt; &quot;mysql-share-space&quot;  }}output {  if &quot;mysql-share-space&quot; in [tags] {        elasticsearch {         hosts=&gt;[&quot;127.0.0.1:8902&quot;]         index =&gt; &quot;hedianzhan&quot;         document_type =&gt; &quot;share_space&quot;         document_id =&gt; &quot;%{space_id}&quot;        }        stdout {          codec =&gt; rubydebug        }  }}</code></pre><p>It will push rows in the “share_space” table left join area, district, industry table to Elasticsearch. The “space_id” column is an auto increment primary key.</p><p>You can run the Logstash using <code>bin/logstash -f logstash-config.conf</code> command.</p><p>This configuration will present the changed rows for having these option.</p><ol><li><p><code>schedule =&gt; &quot;*/5 * * * *&quot;</code>  will run the same configuration file again and again in every 5 minutes</p></li><li><p><code>document_id =&gt; &quot;%{space_id}&quot;</code> , the “document_id” option is for preventing Elasticsearch from creating the same documents again and again. Here we have told pulgin to use the primary key (“space_id” field) as the unique document id. Then Elasticsearch will not create multiple documents for the same record since it does not create documents with same document id. Then the existing one will get replaced with the newest ones. Then the newly added and changed records’ data will be present at the Elasticsearch.</p></li><li><p>“statement” option with “:sql_last_value”, <code>use_column_value =&gt; true</code>, <code>tracking_column =&gt; update_time</code>, <code>tracking_column_type =&gt; &quot;timestamp&quot;</code>, the “share_space” table has a “update_time” column which gets updated whenever a change is happend to a row. This option will incrementally update the data in the Elasticsearch using a “update_time” column. </p></li></ol><p>Here used the option of “:sql_last_value”, it contains the value that is used as the reference to select data to be retrieved. Initially this is set to Thursday, 1 January 1970. And then it jumps to current time. After that it increments the time using the time period specified in the schedule option.</p><p>The sql_last_value is saved in to a metadata file called .logstash_jdbc_last_run automatically. In Linux, it is inside the home folder.</p><p>The option “use_column_value” is used to only retrieves the data in the table in which “update_time” is greater than the value of the “update_time” of the record which was pushed at last, instead of increasing the value of :sql_last_value according to the scheduler. This is very suitable if the “update_time” is set at the program level instead of the database level(Because Logstash could have run the query at the time the records are saved to the database. Therefore, we may miss some records).</p><p>The option “tracking_column_type” is a time-stamp column. Therefore, we have told that to Logstash using tracking_column_type option in advance. </p><p>The option “last_run_metadata_path” is another useful option. This is very important if you want to run two SQL queries at the same time with two parameters.</p><p>All above are the necessary informantion to work with Logstash JDBC input plugin. Just try.</p><h2 id="go-mysql-elasticsearch"><a href="#go-mysql-elasticsearch" class="headerlink" title="go-mysql-elasticsearch"></a>go-mysql-elasticsearch</h2><p>go-mysql-elasticsearch is a service syncing your MySQL data into Elasticsearch automatically.<br>It uses <code>mysqldump</code> to fetch the origin data at first, then syncs data incrementally with binlog.</p><p>You can get the information from “<a href="https://github.com/siddontang/go-mysql-elasticsearch&quot;" target="_blank" rel="noopener">https://github.com/siddontang/go-mysql-elasticsearch&quot;</a> .</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Elasticsearch-amp-MySQL&quot;&gt;&lt;a href=&quot;#Elasticsearch-amp-MySQL&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch &amp;amp; MySQL&quot;&gt;&lt;/a&gt;Elasticsearch &amp;
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="ELK" scheme="http://yoursite.com/tags/ELK/"/>
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud</title>
    <link href="http://yoursite.com/2019/01/19/Spring%20Cloud/"/>
    <id>http://yoursite.com/2019/01/19/Spring Cloud/</id>
    <published>2019-01-19T12:40:58.000Z</published>
    <updated>2019-06-12T11:57:50.442Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spring-Cloud"><a href="#Spring-Cloud" class="headerlink" title="Spring Cloud"></a>Spring Cloud</h1><p>Technologies involved:</p><ul><li>Spring Cloud Netflix Eureka              -&gt;   diretory for all APIs</li><li>Spring Cloud Netflix Ribbon               -&gt;   network cops for all communications</li><li>Spring Cloud Netflix Hystrix              -&gt;   re-router/circuit breaker</li><li>Spring Cloud Netflix Hystrix Dashborad -&gt;   cctv cameras for all rest calls</li><li>Spring Cloud Netflix Zuul              -&gt;   gatekeepers for APIs</li><li>Spring Config Server                      -&gt;   babysitter for configurations of all APIs</li><li>Spring Cloud Sleuth                      -&gt;   tracer for All APIs</li><li>Dockers                                  -&gt;   big smiling fish thingy, for building, shipping &amp; running apps </li></ul><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ol><li>application.yml  vs  bootstrap.yml</li><li>spring boot actuator 监控微服务实例</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Spring-Cloud&quot;&gt;&lt;a href=&quot;#Spring-Cloud&quot; class=&quot;headerlink&quot; title=&quot;Spring Cloud&quot;&gt;&lt;/a&gt;Spring Cloud&lt;/h1&gt;&lt;p&gt;Technologies involved:&lt;/p&gt;
&lt;ul
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="spring cloud" scheme="http://yoursite.com/tags/spring-cloud/"/>
    
  </entry>
  
  <entry>
    <title>java队列分析</title>
    <link href="http://yoursite.com/2018/12/25/%E9%98%9F%E5%88%97%E5%8E%9F%E7%90%86/"/>
    <id>http://yoursite.com/2018/12/25/队列原理/</id>
    <published>2018-12-25T11:54:03.000Z</published>
    <updated>2019-06-12T11:56:28.514Z</updated>
    
    <content type="html"><![CDATA[<h2 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a>LinkedBlockingQueue</h2><p>take(), poll()通过ReentrantLock独占锁保证线程安全； 通过Codition进行通知</p><ol><li>ArrayBlockingQueue vs LinkedBlockingQueue</li></ol><ul><li><p>相同点： </p><ul><li>ArrayBlockingQueue与LinkdedBlockingQueue都实现自BlockingQueue。 这个接口从队列中取元素时，当队列为空会等待到队列不为空； 当存入一个元素，没有足够的空间时，会等待到有空余位置。</li><li>原则都是FIFO(first in first out)</li></ul></li><li><p>不同点： </p><ul><li>ArrayBlockingQueue是由数组实现，LinkedBlockingQueue则由链表数据结构实现；</li><li>ArrayBlockingQueue是有界队列，创建时需要指定容量; LinkedBlockingQueue则不强制指定容量 </li></ul></li></ul><ol start="2"><li>LinkedBlockingQueue vs ConcurrentLinkedQueue</li></ol><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>在秒杀活动中：</p><ul><li><p>ArrayBlockingQueue是初始容量固定的阻塞队列，我们可以用来作为数据库模块成功竞拍的队列，比如有10个商品，那么我们就设定一个10大小的数组队列。数据库主要是使用一个ArrayBlockingQueue来暂存有可能成功的用户请求。</p></li><li><p>ConcurrentLinkedQueue使用的是CAS原语无锁队列实现，是一个异步队列，入队的速度很快，出队进行了加锁，性能稍慢。由于秒杀系统入队需求要远大于出队需求，一般不会出现队空的情况，所以我们可以选择ConcurrentLinkedQueue来作为我们的请求队列实现。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;LinkedBlockingQueue&quot;&gt;&lt;a href=&quot;#LinkedBlockingQueue&quot; class=&quot;headerlink&quot; title=&quot;LinkedBlockingQueue&quot;&gt;&lt;/a&gt;LinkedBlockingQueue&lt;/h2&gt;&lt;p&gt;ta
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>postman设置全局变量</title>
    <link href="http://yoursite.com/2018/12/13/postman%E8%AE%BE%E7%BD%AE%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F/"/>
    <id>http://yoursite.com/2018/12/13/postman设置全局变量/</id>
    <published>2018-12-13T13:06:37.000Z</published>
    <updated>2019-06-12T11:58:57.239Z</updated>
    
    <content type="html"><![CDATA[<ol><li>在Tests中写js, 可以在View-&gt;show postman console中查看调试结果</li></ol><pre><code>console.log(pm.response.json().access_token);console.log(pm.environment.get(&quot;Authorization&quot;))pm.environment.set(&quot;Authorization&quot;, pm.response.json().access_token);</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;在Tests中写js, 可以在View-&amp;gt;show postman console中查看调试结果&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;console.log(pm.response.json().access_token);
console.log
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>非空判断</title>
    <link href="http://yoursite.com/2018/11/17/%E4%BC%98%E9%9B%85%E7%9A%84%E9%9D%9E%E7%A9%BA%E5%88%A4%E6%96%AD/"/>
    <id>http://yoursite.com/2018/11/17/优雅的非空判断/</id>
    <published>2018-11-17T14:57:00.000Z</published>
    <updated>2019-06-12T11:55:06.851Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Optinal"><a href="#Optinal" class="headerlink" title="Optinal"></a>Optinal</h2><h2 id="Preconditions"><a href="#Preconditions" class="headerlink" title="Preconditions"></a>Preconditions</h2><h2 id="Asserts-notNull"><a href="#Asserts-notNull" class="headerlink" title="Asserts.notNull()"></a>Asserts.notNull()</h2><p>项目架构应该使用异常机制处理逻辑上的错误，这样可以使用切点统一进行捕捉，代码可读性更高，后期维护成本更低，只是会消耗一点点性能，这点性能，项目还是承受得起的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Optinal&quot;&gt;&lt;a href=&quot;#Optinal&quot; class=&quot;headerlink&quot; title=&quot;Optinal&quot;&gt;&lt;/a&gt;Optinal&lt;/h2&gt;&lt;h2 id=&quot;Preconditions&quot;&gt;&lt;a href=&quot;#Preconditions&quot; class
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>一台电脑，两个及多个git账号配置</title>
    <link href="http://yoursite.com/2018/11/13/%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E5%A4%9A%E4%B8%AAgithub%E5%B8%90%E5%8F%B7/"/>
    <id>http://yoursite.com/2018/11/13/一台电脑多个github帐号/</id>
    <published>2018-11-13T08:25:47.000Z</published>
    <updated>2018-11-14T11:56:58.294Z</updated>
    
    <content type="html"><![CDATA[<ol><li>生成两[三]个ssh公钥私钥<br>假定其中一个是id_rsa, 另一个时id_rsa_two<pre class=" language-bash"><code class="language-bash">ssh-keyten -t rsa -C 32355788@qq.com</code></pre></li></ol><ol start="2"><li><p>复制公钥<br>把生成好的ssh的公钥相对应复制到github[/gitlab]的settings中的SSH and GPG keys</p></li><li><p>配置config文件<br>如果在.ssh/下没有config文件，可以touch config<br><img src="dir.jpg" alt="目录"></p></li></ol><pre class=" language-bash"><code class="language-bash">   <span class="token comment" spellcheck="true">##可缺省，此时ssh -T git@github.com,默认就是和拥有id_rsa.pub的github账号对接。</span>   <span class="token comment" spellcheck="true">#github server one</span>   Host github              <span class="token comment" spellcheck="true">#域名地址的别名</span>   Hostname github.com      <span class="token comment" spellcheck="true">#这个是真实的域名地址</span>   User <span class="token function">git</span>                     <span class="token comment" spellcheck="true">#配置使用用户名</span>   IdentityFile ~/.ssh/id_rsa   <span class="token comment" spellcheck="true">#这里是id_rsa的地址</span>​   <span class="token comment" spellcheck="true">#github server two</span>   Host github_two   Hostname github.com   User <span class="token function">git</span>   IdentityFile ~/.ssh/id_rsa_two​   <span class="token comment" spellcheck="true">##如果有第三个或者更多</span>   <span class="token comment" spellcheck="true">#gitab server</span>   Host gitlab   Hostname gitlab.com   User <span class="token function">git</span>   IdentityFile ~/.ssh/id_rsa_gitlab​</code></pre><ol start="4"><li>测试</li></ol><pre class=" language-bash"><code class="language-bash"><span class="token function">ssh</span> -T git@gihub   <span class="token comment" spellcheck="true">#如果配置正确会提示</span>   Hi your name one <span class="token keyword">in</span> github <span class="token operator">!</span> You<span class="token string">'ve successfully authenticated, but GitHub does not provide shell access.​   ssh -T git@gihub_two   #如果配置正确会提示   Hi your name two in github ! You'</span>ve successfully authenticated, but GitHub does not provide shell access.​   <span class="token function">ssh</span> -T git@gitlab   <span class="token comment" spellcheck="true">#如果配置正确会提示</span>   Welcome to GitLab, Your GitLab nickname<span class="token operator">!</span>　</code></pre><ol start="5"><li>Clone 项目到本地<br>在工作目录下，首先先git init，然后才能使用git命令clone项目到本地  </li></ol><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#之前的方式:单个账号</span><span class="token function">git</span> clone git@github.com:firstAccount/xxx.git <span class="token comment" spellcheck="true">#缺省config配置时</span><span class="token function">git</span> clone git@github:firstAccount/xxx.git <span class="token comment" spellcheck="true">#config配置后，等价于第一条语句</span><span class="token comment" spellcheck="true">#现在要改为，git clone git@域名别称：用户名/项目名</span><span class="token function">git</span> clone git@github_two:secondAccount/xxx.git //就是使用域名地址的别名来区分<span class="token function">git</span> clone git@gitlab:gitlabAccount/xxx.git</code></pre><ol start="6"><li>配置本地git用户名和邮箱(非必须项)<br>如果首次push repo没有配置git的账号和邮箱，可以如下配置  </li></ol><pre class=" language-bash"><code class="language-bash">   <span class="token comment" spellcheck="true">#全局配置</span>   <span class="token function">git</span> config --global user.name <span class="token string">"Your name"</span>   <span class="token function">git</span> config --global user.email your_email@gmail.com​   <span class="token comment" spellcheck="true">##非必须项</span>   <span class="token comment" spellcheck="true">#局部配置，如果没有局部配置，默认用全局配置否则优先使用局部配置</span>   <span class="token function">cd</span> ~/workspace/github_two/   <span class="token function">git</span> init   <span class="token function">git</span> config  user.name <span class="token string">"Your name"</span>   <span class="token function">git</span> config  user.email your_email@gmail.com​</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;生成两[三]个ssh公钥私钥&lt;br&gt;假定其中一个是id_rsa, 另一个时id_rsa_two&lt;pre class=&quot; language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;ssh-keyten -t rsa -C 3235578
      
    
    </summary>
    
    
      <category term="工具" scheme="http://yoursite.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>Kibana</title>
    <link href="http://yoursite.com/2018/10/12/Kibanna/"/>
    <id>http://yoursite.com/2018/10/12/Kibanna/</id>
    <published>2018-10-12T11:19:27.000Z</published>
    <updated>2019-06-12T11:52:14.627Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h1><p>Kibana is an open source analytics and visualization platform designed to work with Elasticsearch. You use Kibana to search, view, and interact with data stored in Elasticsearch indices. You can easily perfrom advanced data analysis and visualize your data in a variety of charts, tables, and maps.</p><p>Kibanna是开源的，设计用来跟Elasticsearch协同工作的分析、可视化平台。你可以用Kibana对储存在Elasticsearch索引中的数据进行搜索、查看、互动。你可以轻易地执行高级数据分析，使用丰富的图形、表格、地图对数据可视化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Kibana&quot;&gt;&lt;a href=&quot;#Kibana&quot; class=&quot;headerlink&quot; title=&quot;Kibana&quot;&gt;&lt;/a&gt;Kibana&lt;/h1&gt;&lt;p&gt;Kibana is an open source analytics and visualization p
      
    
    </summary>
    
    
      <category term="ELK" scheme="http://yoursite.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>Windows下快速启动多个spring cloud服务</title>
    <link href="http://yoursite.com/2018/10/03/Windows%E4%B8%8B%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8%E5%A4%9A%E4%B8%AAspring%20cloud%E6%9C%8D%E5%8A%A1/"/>
    <id>http://yoursite.com/2018/10/03/Windows下快速启动多个spring cloud服务/</id>
    <published>2018-10-03T14:48:43.000Z</published>
    <updated>2019-06-12T11:43:59.370Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Windows下快速启动多个spring-cloud服务"><a href="#Windows下快速启动多个spring-cloud服务" class="headerlink" title="Windows下快速启动多个spring cloud服务"></a>Windows下快速启动多个spring cloud服务</h1><ol><li>创建start.bat文件，命令行下启动，这是运行在后台服务的，这样就可以不用在编辑器中一个一个启动服务，还可以防止编辑器闪动时，又要重新启动。</li></ol><pre><code>@echo offstart javaw -jar E:\jProjects\ManagementSystem\weifeimanagementsystem\springcloud\sc-eureka\target\sc-eureka.jarstart javaw -jar E:\jProjects\ManagementSystem\weifeimanagementsystem\springcloud\sc-zuul\target\sc-zuul.jarstart javaw -jar E:\jProjects\ManagementSystem\weifeimanagementsystem\springcloud\sc-config\target\sc-config.jarstart javaw -jar E:\jProjects\ManagementSystem\weifeimanagementsystem\tenant\tenant-authserver\target\tenant-authserver.jarstart javaw -jar E:\jProjects\ManagementSystem\weifeimanagementsystem\tenant\tenant-companysys\target\tenant-companysys.jarexit</code></pre><ol start="2"><li>另外如果启动服务报端口被占用的错误，可通过以下步骤停止占用端口的进程</li></ol><ul><li><code>netstat -ano | findstr &quot;8080&quot;</code></li><li><code>taskkill -f -pid 19281</code></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Windows下快速启动多个spring-cloud服务&quot;&gt;&lt;a href=&quot;#Windows下快速启动多个spring-cloud服务&quot; class=&quot;headerlink&quot; title=&quot;Windows下快速启动多个spring cloud服务&quot;&gt;&lt;/a&gt;Wi
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>spring cloud网关</title>
    <link href="http://yoursite.com/2018/09/26/spring%20cloud%E7%BD%91%E5%85%B3/"/>
    <id>http://yoursite.com/2018/09/26/spring cloud网关/</id>
    <published>2018-09-26T12:21:14.000Z</published>
    <updated>2019-06-12T11:57:42.633Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常用服务"><a href="#常用服务" class="headerlink" title="常用服务"></a>常用服务</h2><ol><li>zuul</li><li>gateway</li></ol><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><ol><li>动态路由</li><li>限流</li><li>验证与安全保障</li><li>审查与监控</li><li>压力测试？</li><li>负载分配</li></ol><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>zuul也是基于spring boot的应用，本质上也是个web servlet应用。提供动态路由、监控、弹性、安全等边缘服务的框架。</p><h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><ol><li>过滤器机制 </li></ol><p>zuul的核心是一系列的filters, 其作用可以类比Servlet框架的Filter, 或者AOP。</p><p>zuul中定义了四种标准过滤器类型：</p><ul><li>PRE: 这种过滤器在请求被路由之前调用，我们可利用这种过滤器实现身份证，在集群中选择请求的微服务，记录调试信息等。</li><li>ROUTING: 这种过滤器将请求路由到微服务。</li><li>POST: 这种这滤器在路由到微服务以后执行，这种过滤器可用来为响应添加标准的HTTP Header, 收集统计信息和指标，将响应从微服务发送给客户端等</li><li>ERROR: 在其他阶段发生错误时执行该过滤器</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;常用服务&quot;&gt;&lt;a href=&quot;#常用服务&quot; class=&quot;headerlink&quot; title=&quot;常用服务&quot;&gt;&lt;/a&gt;常用服务&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;zuul&lt;/li&gt;
&lt;li&gt;gateway&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;作用&quot;&gt;&lt;a href=&quot;#作
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="spring cloud" scheme="http://yoursite.com/tags/spring-cloud/"/>
    
  </entry>
  
  <entry>
    <title>java 正则</title>
    <link href="http://yoursite.com/2018/09/04/java%20%E6%AD%A3%E5%88%99/"/>
    <id>http://yoursite.com/2018/09/04/java 正则/</id>
    <published>2018-09-04T14:59:50.000Z</published>
    <updated>2019-06-12T11:43:59.214Z</updated>
    
    <content type="html"><![CDATA[<h1 id="java-正则"><a href="#java-正则" class="headerlink" title="java 正则"></a>java 正则</h1><h2 id="提取匹配的字符串"><a href="#提取匹配的字符串" class="headerlink" title="提取匹配的字符串"></a>提取匹配的字符串</h2><pre><code>         String str = &quot;seass luohanqunbe@qq.com #ba&quot;;        Pattern emailer = Pattern.compile(&quot;\\w+?@\\w+?.com&quot;);        Matcher matcher = emailer.matcher(str);        if(matcher.find()) {            String mat = matcher.group();            System.out.println(mat);        }</code></pre><blockquote><blockquote><p>group()方法要先find(), 不然是会报错的。 “java.lang.IllegalStateException: No match found”<br>\w+ 匹配包括下划线的任何单词字符一个或多个，?防止贪婪匹配，尽可能少地匹配</p></blockquote></blockquote><pre><code>        String str = &quot; # 你在干吗 # &quot;;        Pattern pattern = Pattern.compile(&quot;(?&lt;=#).*?(?=#)&quot;);        Matcher matcher = pattern.matcher(str);        if(matcher.find()) {            String matchStr = matcher.group();            System.out.println(matchStr);        }</code></pre><blockquote><blockquote><p>获取两个#号之间的文字，不包括#号</p></blockquote></blockquote><h2 id="特殊正则分析"><a href="#特殊正则分析" class="headerlink" title="特殊正则分析"></a>特殊正则分析</h2><ol><li>^((+86)|(86))?(13)\d{9}$   以+86或者86开头的，?表示0或者1个， 以13开头的，后面9位数字， 匹配电话号码</li><li>^[a-zA-Z0-9_-]+@[a-zA-Z0-9_-]+(.[a-zA-Z0-9_-]+)+$   以字母、数字、下划线、中划线一个以上开头的邮箱验证</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;java-正则&quot;&gt;&lt;a href=&quot;#java-正则&quot; class=&quot;headerlink&quot; title=&quot;java 正则&quot;&gt;&lt;/a&gt;java 正则&lt;/h1&gt;&lt;h2 id=&quot;提取匹配的字符串&quot;&gt;&lt;a href=&quot;#提取匹配的字符串&quot; class=&quot;headerli
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>秒杀架构</title>
    <link href="http://yoursite.com/2018/08/28/%E7%A7%92%E6%9D%80%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2018/08/28/秒杀架构/</id>
    <published>2018-08-28T13:41:58.000Z</published>
    <updated>2019-06-12T11:43:59.542Z</updated>
    
    <content type="html"><![CDATA[<h1 id="秒杀架构"><a href="#秒杀架构" class="headerlink" title="秒杀架构"></a>秒杀架构</h1><h2 id="秒杀业务分析"><a href="#秒杀业务分析" class="headerlink" title="秒杀业务分析"></a>秒杀业务分析</h2><p>正常电子商务流程:</p><ol><li>查询商品；</li><li>创建订单；</li><li>扣减库存；</li><li>更新订单；</li><li>付款；</li><li>卖家发货；</li></ol><h2 id="技术挑战"><a href="#技术挑战" class="headerlink" title="技术挑战"></a>技术挑战</h2><p>假设某网站秒杀活动只推出一件商品，预计会吸引1万人参加活动，也就说最大并发请求数是10000，秒杀系统需要面对的技术挑战有：</p><ol><li>对现有网站业务造成冲击</li></ol><p>秒杀活动只是网站营销的一个附加活动，这个活动具有时间短，并发访问量大的特点，如果和网站原有应用部署在一起，必然会对现有业务造成冲击，稍有不慎可能导致整个网站瘫痪。</p><blockquote><blockquote><p>解决方案：将秒杀系统独立部署，甚至使用独立域名，使其与网站完全隔离。</p></blockquote></blockquote><ol start="2"><li>高并发下的应用、数据库负载</li></ol><p>用户在秒杀开始前，通过不停刷新浏览器页面以保证不会错过秒杀，这些请求如果按照一般的网站应用架构，访问应用服务器、连接数据库，会对应用服务器和数据库服务器造成负载压力。</p><blockquote><blockquote><p>解决方案：重新设计秒杀商品页面，不使用网站原来的商品详细页面，页面内容静态化，用户请求不需要经过应用服务。</p></blockquote></blockquote><ol start="3"><li>突然增加的网络及服务器带宽</li></ol><p>假设商品页面大小200K（主要是商品图片大小），那么需要的网络和服务器带宽是2G（200K×10000），这些网络带宽是因为秒杀活动新增的，超过网站平时使用的带宽。</p><blockquote><blockquote><p>解决方案：因为秒杀新增的网络带宽，必须和运营商重新购买或者租借。为了减轻网站服务器的压力，需要将秒杀商品页面缓存在CDN，同样需要和CDN服务商临时租借新增的出口带宽。</p></blockquote></blockquote><ol start="4"><li>直接下单</li></ol><p>秒杀的游戏规则是到了秒杀才能开始对商品下单购买，在此时间点之前，只能浏览商品信息，不能下单。而下单页面也是一个普通的URL，如果得到这个URL，不用等到秒杀开始就可以下单了。</p><blockquote><blockquote><p>解决方案：为了避免用户直接访问下单页面URL，需要将改URL动态化，即使秒杀系统的开发者也无法在秒杀开始前访问下单页面的URL。办法是在下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到。</p></blockquote></blockquote><ol start="5"><li>如何控制秒杀商品页面购买按钮的点亮</li></ol><p>购买按钮只有在秒杀开始的时候才能点亮，在此之前是灰色的。如果该页面是动态生成的，当然可以在服务器端构造响应页面输出，控制该按钮是灰色还是点亮，但是为了减轻服务器端负载压力，更好地利用CDN、反向代理等性能优化手段，该页面被设计为静态页面，缓存在CDN、反向代理服务器上，甚至用户浏览器上。秒杀开始时，用户刷新页面，请求根本不会到达应用服务器。</p><blockquote><blockquote><p>解决方案：使用JavaScript脚本控制，在秒杀商品静态页面中加入一个JavaScript文件引用，该JavaScript文件中包含秒杀开始标志为否；当秒杀开始的时候生成一个新的JavaScript文件（文件名保持不变，只是内容不一样），更新秒杀开始标志为是，加入下单页面的URL及随机数参数（这个随机数只会产生一个，即所有人看到的URL都是同一个，服务器端可以用redis这种分布式缓存服务器来保存随机数），并被用户浏览器加载，控制秒杀商品页面的展示。这个JavaScript文件的加载可以加上随机版本号（例如xx.js?v=32353823），这样就不会被浏览器、CDN和反向代理服务器缓存。<br>这个JavaScript文件非常小，即使每次浏览器刷新都访问JavaScript文件服务器也不会对服务器集群和网络带宽造成太大压力。</p></blockquote></blockquote><ol start="6"><li>如何只允许第一个提交的订单被发送到订单子系统</li></ol><p>由于最终能够成功秒杀到商品的用户只有一个，因此需要在用户提交订单时，检查是否已经有订单提交。如果已经有订单提交成功，则需要更新 JavaScript文件，更新秒杀开始标志为否，购买按钮变灰。事实上，由于最终能够成功提交订单的用户只有一个，为了减轻下单页面服务器的负载压力，可以控制进入下单页面的入口，只有少数用户能进入下单页面，其他用户直接进入秒杀结束页面。</p><blockquote><blockquote><p>解决方案：假设下单服务器集群有10台服务器，每台服务器只接受最多10个下单请求。在还没有人提交订单成功之前，如果一台服务器已经有十单了，而有的一单都没处理，可能出现的用户体验不佳的场景是用户第一次点击购买按钮进入已结束页面，再刷新一下页面，有可能被一单都没有处理的服务器处理，进入了填写订单的页面，可以考虑通过cookie的方式来应对，符合一致性原则。当然可以采用最少连接的负载均衡算法，出现上述情况的概率大大降低。</p></blockquote></blockquote><ol start="7"><li>如何进行下单前置检查</li></ol><p>下单服务器检查本机已处理的下单请求数目：</p><ul><li>如果超过10条，直接返回已结束页面给用户；</li><li>如果未超过10条，则用户可进入填写订单及确认页面；</li></ul><p>检查全局已提交订单数目：</p><ul><li>已超过秒杀商品总数，返回已结束页面给用户；</li><li>未超过秒杀商品总数，提交到子订单系统；</li></ul><ol start="8"><li>秒杀一般是定时上架</li></ol><p>该功能实现方式很多。不过目前比较好的方式是：提前设定好商品的上架时间，用户可以在前台看到该商品，但是无法点击“立即购买”的按钮。但是需要考虑的是，有人可以绕过前端的限制，直接通过URL的方式发起购买，这就需要在前台商品页面，以及bug页面到后端的数据库，都要进行时钟同步。越在后端控制，安全性越高。</p><p>定时秒杀的话，就要避免卖家在秒杀前对商品做编辑带来的不可预期的影响。这种特殊的变更需要多方面评估。一般禁止编辑，如需变更，可以走数据订正的流程。</p><ol start="9"><li>减库存的操作</li></ol><p>有两种选择，一种是拍下减库存 另外一种是付款减库存；目前采用的“拍下减库存”的方式，拍下就是一瞬间的事，对用户体验会好些。</p><ol start="10"><li>库存会带来“超卖”的问题：售出数量多于库存数量</li></ol><p>由于库存并发更新的问题，导致在实际库存已经不足的情况下，库存依然在减，导致卖家的商品卖得件数超过秒杀的预期。方案：采用乐观锁</p><pre><code>update auction_auctions setquantity = #inQuantity#where auction_id = #itemId# and quantity = #dbQuantity#</code></pre><p>还有一种方式，会更好些，叫做尝试扣减库存，扣减库存成功才会进行下单逻辑：</p><pre><code>update auction_auctions set quantity = quantity-#count# where auction_id = #itemId# and quantity &gt;= #count# </code></pre><ol start="11"><li>秒杀器的应对</li></ol><p>秒杀器一般下单个购买及其迅速，根据购买记录可以甄别出一部分。可以通过校验码达到一定的方法，这就要求校验码足够安全，不被破解，采用的方式有：秒杀专用验证码，电视公布验证码，秒杀答题。</p><h2 id="秒杀架构原则"><a href="#秒杀架构原则" class="headerlink" title="秒杀架构原则"></a>秒杀架构原则</h2><ol><li>尽量将请求拦截在系统上游</li></ol><p>传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小【一趟火车其实只有2000张票，200w个人来买，基本没有人能买成功，请求有效率为0】。</p><ol start="2"><li>读多写少的常用多使用缓存</li></ol><p>这是一个典型的读多写少的应用场景【一趟火车其实只有2000张票，200w个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%】，非常适合使用缓存。                    </p><h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><p>秒杀系统为秒杀而设计，不同于一般的网购行为，参与秒杀活动的用户更关心的是如何能快速刷新商品页面，在秒杀开始的时候抢先进入下单页面，而不是商品详情等用户体验细节，因此秒杀系统的页面设计应尽可能简单。</p><p>商品页面中的购买按钮只有在秒杀活动开始的时候才变亮，在此之前及秒杀商品卖出后，该按钮都是灰色的，不可以点击。</p><p>下单表单也尽可能简单，购买数量只能是一个且不可以修改，送货地址和付款方式都使用用户默认设置，没有默认也可以不填，允许等订单提交后修改；只有第一个提交的订单发送给网站的订单子系统，其余用户提交订单后只能看到秒杀结束页面。</p><h3 id="前端层设计"><a href="#前端层设计" class="headerlink" title="前端层设计"></a>前端层设计</h3><p>首先要有一个展示秒杀商品的页面，在这个页面上做一个秒杀活动开始的倒计时，在准备阶段内用户会陆续打开这个秒杀的页面， 并且可能不停的刷新页面。这里需要考虑两个问题：</p><ol><li>是秒杀页面的展示</li></ol><p>我们知道一个html页面还是比较大的，即使做了压缩，http头和内容的大小也可能高达数十K，加上其他的css， js，图片等资源，如果同时有几千万人参与一个商品的抢购，一般机房带宽也就只有1G10G，网络带宽就极有可能成为瓶颈，所以这个页面上各类静态资源首先应分开存放，然后放到cdn节点上分散压力，由于CDN节点遍布全国各地，能缓冲掉绝大部分的压力，而且还比机房带宽便宜</p><ol start="2"><li>是倒计时</li></ol><p>出于性能原因这个一般由js调用客户端本地时间，就有可能出现客户端时钟与服务器时钟不一致，另外服务器之间也是有可能出现时钟不一致。客户端与服务器时钟不一致可以采用客户端定时和服务器同步时间。</p><p>这里考虑一下性能问题，用于同步时间的接口由于不涉及到后端逻辑，只需要将当前web服务器的时间发送给客户端就可以了，因此速度很快，就我以前测试的结果来看，一台标准的web服务器2W+QPS不会有问题，如果100W人同时刷，100W QPS也只需要50台web，一台硬件LB就可以了。</p><p>并且web服务器群是可以很容易的横向扩展的(LB+DNS轮询)，这个接口可以只返回一小段json格式的数据，而且可以优化一下减少不必要cookie和其他http头的信息，所以数据量不会很大，一般来说网络不会成为瓶颈，即使成为瓶颈也可以考虑多机房专线连通，加智能DNS的解决方案；web服务器之间时间不同步可以采用统一时间服务器的方式，比如每隔1分钟所有参与秒杀活动的web服务器就与时间服务器做一次时间同步。秒杀系统必须考虑的 3 个技术问题！这篇也不错。</p><p>~浏览器层请求拦截~</p><p>产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求;<br>JS层面，限制用户在x秒之内只能提交一次请求;</p><h3 id="站点层设计"><a href="#站点层设计" class="headerlink" title="站点层设计"></a>站点层设计</h3><p>前端层的请求拦截，只能拦住小白用户（不过这是99%的用户哟），高端的程序员根本不吃这一套，写个for循环，直接调用你后端的http请求，怎么整？</p><p>同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面<br>同一个item的查询，例如手机车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面<br>如此限流，又有99%的流量会被拦截在站点层。</p><h3 id="服务层设计"><a href="#服务层设计" class="headerlink" title="服务层设计"></a>服务层设计</h3><p>站点层的请求拦截，只能拦住普通程序员，高级黑客，假设他控制了10w台肉鸡（并且假设买票不需要实名认证），这下uid的限制不行了吧？怎么整？</p><ul><li>大哥，我是服务层，我清楚的知道小米只有1万部手机，我清楚的知道一列火车只有2000张车票，我透10w个请求去数据库有什么意义呢？对于写请求，做请求队列，每次只透过有限的写请求去数据层，如果均成功再放下一批，如果库存不够则队列里的写请求全部返回“已售完”；</li><li>对于读请求，还用说么？cache来抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的；</li></ul><p>如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了。</p><ul><li>用户请求分发模块：使用Nginx或Apache将用户的请求分发到不同的机器上。</li><li>用户请求预处理模块：判断商品是不是还有剩余来决定是不是要处理该请求。</li><li>用户请求处理模块：把通过预处理的请求封装成事务提交给数据库，并返回是否成功。</li><li>数据库接口模块：该模块是数据库的唯一接口，负责与数据库交互，提供RPC接口供查询是否秒杀结束、剩余数量等信息。</li></ul><ol><li>用户请求预处理模块</li></ol><p>经过HTTP服务器的分发后，单个服务器的负载相对低了一些，但总量依然可能很大，如果后台商品已经被秒杀完毕，那么直接给后来的请求返回秒杀失败即可，不必再进一步发送事务了，示例代码可以如下所示：</p><pre><code>package seckill;import org.apache.http.HttpRequest;/**    * 预处理阶段，把不必要的请求直接驳回，必要的请求添加到队列中进入下一阶段.    */public class PreProcessor {      // 商品是否还有剩余      private static boolean reminds = true;      private static void forbidden() {          // Do something.      }      public static boolean checkReminds() {          if (reminds) {              // 远程检测是否还有剩余，该RPC接口应由数据库服务器提供，不必完全严格检查.              if (!RPC.checkReminds()) {                  reminds = false;              }          }          return reminds;      }    /**     * 每一个HTTP请求都要经过该预处理.     */      public static void preProcess(HttpRequest request) {          if (checkReminds()) {              // 一个并发的队列              RequestQueue.queue.add(request);          } else {              // 如果已经没有商品了，则直接驳回请求即可.              forbidden();          }      }}</code></pre><ol start="2"><li>并发队列的选择</li></ol><p>Java的并发包提供了三个常用的并发队列实现，分别是：ConcurrentLinkedQueue、LinkedBlockingQueue和ArrayBlockingQueue。</p><ul><li>ArrayBlockingQueue是初始容量固定的阻塞队列，我们可以用来作为数据库模块成功竞拍的队列，比如有10个商品，那么我们就设定一个10大小的数组队列。</li><li>ConcurrentLinkedQueue使用的是CAS原语无锁队列实现，是一个异步队列，入队的速度很快，出队进行了加锁，性能稍慢。</li><li>LinkedBlockingQueue也是阻塞的队列，入队和出队都用了加锁，当队空的时候线程会暂时阻塞。</li></ul><p>由于我们的系统入队需求要远大于出队需求，一般不会出现队空的情况，所以我们可以选择ConcurrentLinkedQueue来作为我们的请求队列实现：</p><pre><code>package seckill;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ConcurrentLinkedQueue;import org.apache.http.HttpRequest;public class RequestQueue {        public static ConcurrentLinkedQueue&lt;HttpRequest&gt; queue = new ConcurrentLinkedQueue&lt;HttpRequest&gt;();}</code></pre><ol start="3"><li>用户请求模块</li></ol><pre><code>package seckill;import org.apache.http.HttpRequest;public class Processor {    /**     * 发送秒杀事务到数据库队列.     */    public static void kill(BidInfo info) {        DB.bids.add(info);    }    public static void process() {        BidInfo info = new BidInfo(RequestQueue.queue.poll());        if (info != null) {            kill(info);        }    }}class BidInfo {    BidInfo(HttpRequest request) {        // Do something.    }}</code></pre><ol start="4"><li>数据库模块</li></ol><p>数据库主要是使用一个ArrayBlockingQueue来暂存有可能成功的用户请求。</p><pre><code>package seckill;import java.util.concurrent.ArrayBlockingQueue;/**    * DB应该是数据库的唯一接口.    */public class DB {      public static int count = 10;      public static ArrayBlockingQueue&lt;BidInfo&gt; bids = new ArrayBlockingQueue&lt;BidInfo&gt;(10);      public static boolean checkReminds() {          // TODO          return true;      }      // 单线程操作      public static void bid() {          BidInfo info = bids.poll();          while (count-- &gt; 0) {              // insert into table Bids values(item_id, user_id, bid_date, other)              // select count(id) from Bids where item_id = ?              // 如果数据库商品数量大约总数，则标志秒杀已完成，设置标志位reminds = false.              info = bids.poll();          }      }}</code></pre><h3 id="数据库设计"><a href="#数据库设计" class="headerlink" title="数据库设计"></a>数据库设计</h3><ol><li>基本概念：</li></ol><p>一、 分片解决的是“数据量太大”的问题，也就是通常说的“水平切分”。一旦引入分片，势必有“数据路由”的概念，哪个数据访问哪个库。路由规则通常有3种方法：</p><ul><li>范围：range</li></ul><p>优点：简单，容易扩展<br>缺点：各库压力不均（新号段更活跃）</p><ul><li>哈希：hash 【大部分互联网公司采用的方案二：哈希分库，哈希路由】</li></ul><p>优点：简单，数据均衡，负载均匀<br>缺点：迁移麻烦（2库扩3库数据要迁移）</p><ul><li>路由服务：router-config-server</li></ul><p>优点：灵活性强，业务与路由算法解耦<br>缺点：每次访问数据库前多一次查询</p><p>二、 分组解决“可用性”问题，分组通常通过主从复制的方式实现。</p><ol start="2"><li>设计思路 </li></ol><p>数据库软件架构师平时设计些什么东西呢？至少要考虑以下四点：</p><ul><li>如何保证数据可用性；</li><li>如何提高数据库读性能（大部分应用读多写少，读会先成为瓶颈）；</li><li>如何保证一致性；</li><li>如何提高扩展性；</li></ul><ul><li>如何保证数据的可用性？</li></ul><p>解决可用性问题的思路是=&gt;冗余</p><blockquote><blockquote><p>如何保证站点的可用性？复制站点，冗余站点<br>如何保证服务的可用性？复制服务，冗余服务<br>如何保证数据的可用性？复制数据，冗余数据</p></blockquote></blockquote><p>数据的冗余，会带来一个副作用=&gt;引发一致性问题（先不说一致性问题，先说可用性）。</p><ul><li>如何保证数据库“读”高可用？</li></ul><blockquote><blockquote><p>冗余读库</p></blockquote></blockquote><p>冗余读库带来的副作用？读写有延时，可能不一致。</p><p>＊ 如何保证数据库“写”高可用？</p><p>采用双主互备的方式，可以冗余写库带来的副作用？双写同步，数据可能冲突（例如“自增id”同步冲突），如何解决同步冲突，有两种常见解决方案：</p><ul><li>两个写库使用不同的初始值，相同的步长来增加id：1写库的id为0,2,4,6…；2写库的id为1,3,5,7…；</li><li>不使用数据的id，业务层自己生成唯一的id，保证数据不冲突；</li></ul><p>实际中没有使用上述两种架构来做读写的“高可用”，采用的是“双主当主从用”的方式：</p><p>仍是双主，但只有一个主提供服务（读+写），另一个主是“shadow-master”，只用来保证高可用，平时不提供服务。</p><p>master挂了，shadow-master顶上（vip漂移，对业务层透明，不需要人工介入）。</p><p>这种方式的好处：</p><ul><li>读写没有延时；</li><li>读写高可用；</li></ul><p>不足：</p><ul><li>不能通过加从库的方式扩展读性能；</li><li>资源利用率为50%，一台冗余主没有提供服务；</li></ul><p>那如何提高读性能呢？进入第二个话题，如何提供读性能。</p><p>*　如何扩展读性能 </p><p>提高读性能的方式大致有三种：</p><p>第一种是建立索引。这种方式不展开，要提到的一点是，不同的库可以建立不同的索引。</p><blockquote><blockquote><p>写库不建立索引；<br>线上读库建立线上访问索引，例如uid；<br>线下读库建立线下访问索引，例如time；</p></blockquote></blockquote><p>第二种扩充读性能的方式是，增加从库，这种方法大家用的比较多，但是，存在两个缺点：</p><ul><li>从库越多，同步越慢；</li><li>同步越慢，数据不一致窗口越大（不一致后面说，还是先说读性能的提高）；</li></ul><p>实际中没有采用这种方法提高数据库读性能（没有从库），采用的是增加缓存。常见的缓存架构如下：</p><p>上游是业务应用，下游是主库，从库（读写分离），缓存。实际的玩法：服务+数据库+缓存一套。</p><p>业务层不直接面向db和cache，服务层屏蔽了底层db、cache的复杂性。为什么要引入服务层，今天不展开，采用了“服务+数据库+缓存一套”的方式提供数据访问，用cache提高读性能。</p><p>不管采用主从的方式扩展读性能，还是缓存的方式扩展读性能，数据都要复制多份（主+从，db+cache），一定会引发一致性问题。</p><ul><li>如何保证一致性</li></ul><p>主从数据库的一致性，通常有两种解决方案：</p><ol><li>中间件</li></ol><p>如果某一个key有写操作，在不一致时间窗口内，中间件会将这个key的读操作也路由到主库上。这个方案的缺点是，数据库中间件的门槛较高（百度，腾讯，阿里，360等一些公司有）。</p><ol start="2"><li>强制读主</li></ol><p>上面实际用的“双主当主从用”的架构，不存在主从不一致的问题。第二类不一致，是db与缓存间的不一致：</p><p>常见的缓存架构如上，此时写操作的顺序是：</p><ul><li>淘汰cache；</li><li>写数据库；</li></ul><p>读操作的顺序是：</p><ul><li>读cache，如果cache hit则返回；</li><li>如果cache miss，则读从库；</li><li>读从库后，将数据放回cache；</li></ul><p>在一些异常时序情况下，有可能从【从库读到旧数据（同步还没有完成），旧数据入cache后】，数据会长期不一致。解决办法是“缓存双淘汰”，写操作时序升级为：</p><ul><li>淘汰cache；</li><li>写数据库；</li><li>在经过“主从同步延时窗口时间”后，再次发起一个异步淘汰cache的请求；</li></ul><p>这样，即使有脏数据如cache，一个小的时间窗口之后，脏数据还是会被淘汰。带来的代价是，多引入一次读miss（成本可以忽略）。</p><p>除此之外，最佳实践之一是：建议为所有cache中的item设置一个超时时间。</p><ol start="3"><li>如何提高数据库的扩展性？</li></ol><p>原来用hash的方式路由，分为2个库，数据量还是太大，要分为3个库，势必需要进行数据迁移，有一个很帅气的“数据库秒级扩容”方案。</p><p>如何秒级扩容？</p><p>首先，我们不做2库变3库的扩容，我们做2库变4库（库加倍）的扩容（未来4-&gt;8-&gt;16）</p><p>服务+数据库是一套（省去了缓存），数据库采用“双主”的模式。</p><p>扩容步骤：</p><p>第一步，将一个主库提升;<br>第二步，修改配置，2库变4库（原来MOD2，现在配置修改后MOD4），扩容完成；</p><blockquote><blockquote><p>原MOD2为偶的部分，现在会MOD4余0或者2；原MOD2为奇的部分，现在会MOD4余1或者3；数据不需要迁移，同时，双主互相同步，一遍是余0，一边余2，两边数据同步也不会冲突，秒级完成扩容！</p></blockquote></blockquote><p>最后，要做一些收尾工作：</p><ul><li>将旧的双主同步解除；</li><li>增加新的双主（双主是保证可用性的，shadow-master平时不提供服务）；</li><li>删除多余的数据（余0的主，可以将余2的数据删除掉）；</li></ul><p>这样，秒级别内，我们就完成了2库变4库的扩展。</p><h2 id="大并发带来的挑战"><a href="#大并发带来的挑战" class="headerlink" title="大并发带来的挑战"></a>大并发带来的挑战</h2><h3 id="请求接口的合理设计"><a href="#请求接口的合理设计" class="headerlink" title="请求接口的合理设计"></a>请求接口的合理设计</h3><p>一个秒杀或者抢购页面，通常分为2个部分，一个是静态的HTML等内容，另一个就是参与秒杀的Web后台请求接口。</p><p>通常静态HTML等内容，是通过CDN的部署，一般压力不大，核心瓶颈实际上在后台请求接口上。这个后端接口，必须能够支持高并发请求，同时，非常重要的一点，必须尽可能“快”，在最短的时间里返回用户的请求结果。为了实现尽可能快这一点，接口的后端存储使用内存级别的操作会更好一点。仍然直接面向MySQL之类的存储是不合适的，如果有这种复杂业务的需求，都建议采用异步写入。</p><h3 id="高并发的挑战：一定要“快”"><a href="#高并发的挑战：一定要“快”" class="headerlink" title="高并发的挑战：一定要“快”"></a>高并发的挑战：一定要“快”</h3><p>我们通常衡量一个Web系统的吞吐率的指标是QPS（Query Per Second，每秒处理请求数），解决每秒数万次的高并发场景，这个指标非常关键。举个例子，我们假设处理一个业务请求平均响应时间为100ms，同时，系统内有20台Apache的Web服务器，配置MaxClients为500个（表示Apache的最大连接数目）。</p><p>那么，我们的Web系统的理论峰值QPS为（理想化的计算方式）：</p><blockquote><blockquote><p>20*500/0.1 = 100000 （10万QPS）</p></blockquote></blockquote><p>咦？我们的系统似乎很强大，1秒钟可以处理完10万的请求，5w/s的秒杀似乎是“纸老虎”哈。实际情况，当然没有这么理想。在高并发的实际场景下，机器都处于高负载的状态，在这个时候平均响应时间会被大大增加。</p><p>就Web服务器而言，Apache打开了越多的连接进程，CPU需要处理的上下文切换也越多，额外增加了CPU的消耗，然后就直接导致平均响应时间增加。因此上述的MaxClient数目，要根据CPU、内存等硬件因素综合考虑，绝对不是越多越好。可以通过Apache自带的abench来测试一下，取一个合适的值。然后，我们选择内存操作级别的存储的Redis，在高并发的状态下，存储的响应时间至关重要。网络带宽虽然也是一个因素，不过，这种请求数据包一般比较小，一般很少成为请求的瓶颈。负载均衡成为系统瓶颈的情况比较少，在这里不做讨论哈。</p><p>那么问题来了，假设我们的系统，在5w/s的高并发状态下，平均响应时间从100ms变为250ms（实际情况，甚至更多）：</p><blockquote><blockquote><p>20*500/0.25 = 40000 （4万QPS）</p></blockquote></blockquote><p>于是，我们的系统剩下了4w的QPS，面对5w每秒的请求，中间相差了1w。</p><p>然后，这才是真正的恶梦开始。举个例子，高速路口，1秒钟来5部车，每秒通过5部车，高速路口运作正常。突然，这个路口1秒钟只能通过4部车，车流量仍然依旧，结果必定出现大塞车。（5条车道忽然变成4条车道的感觉）。</p><p>同理，某一个秒内，20*500个可用连接进程都在满负荷工作中，却仍然有1万个新来请求，没有连接进程可用，系统陷入到异常状态也是预期之内</p><p>其实在正常的非高并发的业务场景中，也有类似的情况出现，某个业务请求接口出现问题，响应时间极慢，将整个Web请求响应时间拉得很长，逐渐将Web服务器的可用连接数占满，其他正常的业务请求，无连接进程可用。</p><p>更可怕的问题是，是用户的行为特点，系统越是不可用，用户的点击越频繁，恶性循环最终导致“雪崩”（其中一台Web机器挂了，导致流量分散到其他正常工作的机器上，再导致正常的机器也挂，然后恶性循环），将整个Web系统拖垮。</p><h3 id="重启与过载保护"><a href="#重启与过载保护" class="headerlink" title="重启与过载保护"></a>重启与过载保护</h3><p>如果系统发生“雪崩”，贸然重启服务，是无法解决问题的。最常见的现象是，启动起来后，立刻挂掉。这个时候，最好在入口层将流量拒绝，然后再将重启。如果是redis/memcache这种服务也挂了，重启的时候需要注意“预热”，并且很可能需要比较长的时间。</p><p>秒杀和抢购的场景，流量往往是超乎我们系统的准备和想象的。这个时候，过载保护是必要的。如果检测到系统满负载状态，拒绝请求也是一种保护措施。在前端设置过滤是最简单的方式，但是，这种做法是被用户“千夫所指”的行为。更合适一点的是，将过载保护设置在CGI入口层，快速将客户的直接请求返回。</p><h2 id="作弊的手段：进攻与防守"><a href="#作弊的手段：进攻与防守" class="headerlink" title="作弊的手段：进攻与防守"></a>作弊的手段：进攻与防守</h2><p>秒杀和抢购收到了“海量”的请求，实际上里面的水分是很大的。不少用户，为了“抢“到商品，会使用“刷票工具”等类型的辅助工具，帮助他们发送尽可能多的请求到服务器。还有一部分高级用户，制作强大的自动请求脚本。这种做法的理由也很简单，就是在参与秒杀和抢购的请求中，自己的请求数目占比越多，成功的概率越高。</p><p>这些都是属于“作弊的手段”，不过，有“进攻”就有“防守”，这是一场没有硝烟的战斗哈。</p><h3 id="同一个账号，一次性发出多个请求"><a href="#同一个账号，一次性发出多个请求" class="headerlink" title="同一个账号，一次性发出多个请求"></a>同一个账号，一次性发出多个请求</h3><p>部分用户通过浏览器的插件或者其他工具，在秒杀开始的时间里，以自己的账号，一次发送上百甚至更多的请求。实际上，这样的用户破坏了秒杀和抢购的公平性。</p><p>这种请求在某些没有做数据安全处理的系统里，也可能造成另外一种破坏，导致某些判断条件被绕过。例如一个简单的领取逻辑，先判断用户是否有参与记录，如果没有则领取成功，最后写入到参与记录中。这是个非常简单的逻辑，但是，在高并发的场景下，存在深深的漏洞。多个并发请求通过负载均衡服务器，分配到内网的多台Web服务器，它们首先向存储发送查询请求，然后，在某个请求成功写入参与记录的时间差内，其他的请求获查询到的结果都是“没有参与记录”。这里，就存在逻辑判断被绕过的风险。</p><p><strong>应对方案：</strong></p><p>在程序入口处，一个账号只允许接受1个请求，其他请求过滤。不仅解决了同一个账号，发送N个请求的问题，还保证了后续的逻辑流程的安全。实现方案，可以通过Redis这种内存缓存服务，写入一个标志位（只允许1个请求写成功，结合watch的乐观锁的特性），成功写入的则可以继续参加。</p><p>或者，自己实现一个服务，将同一个账号的请求放入一个队列中，处理完一个，再处理下一个。</p><h3 id="多个账号，一次性发送多个请求"><a href="#多个账号，一次性发送多个请求" class="headerlink" title="多个账号，一次性发送多个请求"></a>多个账号，一次性发送多个请求</h3><p>很多公司的账号注册功能，在发展早期几乎是没有限制的，很容易就可以注册很多个账号。因此，也导致了出现了一些特殊的工作室，通过编写自动注册脚本，积累了一大批“僵尸账号”，数量庞大，几万甚至几十万的账号不等，专门做各种刷的行为（这就是微博中的“僵尸粉“的来源）。</p><p>举个例子，例如微博中有转发抽奖的活动，如果我们使用几万个“僵尸号”去混进去转发，这样就可以大大提升我们中奖的概率。</p><p>这种账号，使用在秒杀和抢购里，也是同一个道理。例如，iPhone官网的抢购，火车票黄牛党。</p><p><strong>应对方案：</strong></p><p>这种场景，可以通过检测指定机器IP请求频率就可以解决，如果发现某个IP请求频率很高，可以给它弹出一个验证码或者直接禁止它的请求：</p><p>弹出验证码，最核心的追求，就是分辨出真实用户。因此，大家可能经常发现，网站弹出的验证码，有些是“鬼神乱舞”的样子，有时让我们根本无法看清。他们这样做的原因，其实也是为了让验证码的图片不被轻易识别，因为强大的“自动脚本”可以通过图片识别里面的字符，然后让脚本自动填写验证码。实际上，有一些非常创新的验证码，效果会比较好，例如给你一个简单问题让你回答，或者让你完成某些简单操作（例如百度贴吧的验证码）。</p><p>直接禁止IP，实际上是有些粗暴的，因为有些真实用户的网络场景恰好是同一出口IP的，可能会有“误伤“。但是这一个做法简单高效，根据实际场景使用可以获得很好的效果。关注Java技术栈微信公众号，在后台回复关键字：架构，可以获取更多栈长整理的架构干货。</p><h3 id="多个账号，不同IP发送不同请求"><a href="#多个账号，不同IP发送不同请求" class="headerlink" title="多个账号，不同IP发送不同请求"></a>多个账号，不同IP发送不同请求</h3><p>所谓道高一尺，魔高一丈。有进攻，就会有防守，永不休止。这些“工作室”，发现你对单机IP请求频率有控制之后，他们也针对这种场景，想出了他们的“新进攻方案”，就是不断改变IP。</p><p>有同学会好奇，这些随机IP服务怎么来的。有一些是某些机构自己占据一批独立IP，然后做成一个随机代理IP的服务，有偿提供给这些“工作室”使用。还有一些更为黑暗一点的，就是通过木马黑掉普通用户的电脑，这个木马也不破坏用户电脑的正常运作，只做一件事情，就是转发IP包，普通用户的电脑被变成了IP代理出口。通过这种做法，黑客就拿到了大量的独立IP，然后搭建为随机IP服务，就是为了挣钱。</p><p><strong>应对方案：</strong></p><p>说实话，这种场景下的请求，和真实用户的行为，已经基本相同了，想做分辨很困难。再做进一步的限制很容易“误伤“真实用户，这个时候，通常只能通过设置业务门槛高来限制这种请求了，或者通过账号行为的”数据挖掘“来提前清理掉它们。</p><p>僵尸账号也还是有一些共同特征的，例如账号很可能属于同一个号码段甚至是连号的，活跃度不高，等级低，资料不全等等。根据这些特点，适当设置参与门槛，例如限制参与秒杀的账号等级。通过这些业务手段，也是可以过滤掉一些僵尸号。</p><h2 id="高并发下的数据安全"><a href="#高并发下的数据安全" class="headerlink" title="高并发下的数据安全"></a>高并发下的数据安全</h2><p>我们知道在多线程写入同一个文件的时候，会存现“线程安全”的问题（多个线程同时运行同一段代码，如果每次运行结果和单线程运行的结果是一样的，结果和预期相同，就是线程安全的）。如果是MySQL数据库，可以使用它自带的锁机制很好的解决问题，但是，在大规模并发的场景中，是不推荐使用MySQL的。</p><p>秒杀和抢购的场景中，还有另外一个问题，就是“超发”，如果在这方面控制不慎，会产生发送过多的情况。我们也曾经听说过，某些电商搞抢购活动，买家成功拍下后，商家却不承认订单有效，拒绝发货。这里的问题，也许并不一定是商家奸诈，而是系统技术层面存在超发风险导致的。</p><h3 id="超发的原因"><a href="#超发的原因" class="headerlink" title="超发的原因"></a>超发的原因</h3><p>假设某个抢购场景中，我们一共只有100个商品，在最后一刻，我们已经消耗了99个商品，仅剩最后一个。这个时候，系统发来多个并发请求，这批请求读取到的商品余量都是99个，然后都通过了这一个余量判断，最终导致超发。</p><h3 id="悲观锁思路"><a href="#悲观锁思路" class="headerlink" title="悲观锁思路"></a>悲观锁思路</h3><p>解决线程安全的思路很多，可以从“悲观锁”的方向开始讨论。</p><p>悲观锁，也就是在修改数据的时候，采用锁定状态，排斥外部请求的修改。遇到加锁的状态，就必须等待。</p><p>虽然上述的方案的确解决了线程安全的问题，但是，别忘记，我们的场景是“高并发”。也就是说，会很多这样的修改请求，每个请求都需要等待“锁”，某些线程可能永远都没有机会抢到这个“锁”，这种请求就会死在那里。同时，这种请求会很多，瞬间增大系统的平均响应时间，结果是可用连接数被耗尽，系统陷入异常。</p><h3 id="FIFO队列思路"><a href="#FIFO队列思路" class="headerlink" title="FIFO队列思路"></a>FIFO队列思路</h3><p>那好，那么我们稍微修改一下上面的场景，我们直接将请求放入队列中的，采用FIFO（First Input First Output，先进先出），这样的话，我们就不会导致某些请求永远获取不到锁。看到这里，是不是有点强行将多线程变成单线程的感觉哈。</p><p>然后，我们现在解决了锁的问题，全部请求采用“先进先出”的队列方式来处理。那么新的问题来了，高并发的场景下，因为请求很多，很可能一瞬间将队列内存“撑爆”，然后系统又陷入到了异常状态。或者设计一个极大的内存队列，也是一种方案，但是，系统处理完一个队列内请求的速度根本无法和疯狂涌入队列中的数目相比。也就是说，队列内的请求会越积累越多，最终Web系统平均响应时候还是会大幅下降，系统还是陷入异常。 </p><h3 id="乐观锁思路"><a href="#乐观锁思路" class="headerlink" title="乐观锁思路"></a>乐观锁思路</h3><p>这个时候，我们就可以讨论一下“乐观锁”的思路了。乐观锁，是相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败。这样的话，我们就不需要考虑队列的问题，不过，它会增大CPU的计算开销。但是，综合来说，这是一个比较好的解决方案。</p><p>有很多软件和服务都“乐观锁”功能的支持，例如Redis中的watch就是其中之一。通过这个实现，我们保证了数据的安全。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>互联网正在高速发展，使用互联网服务的用户越多，高并发的场景也变得越来越多。电商秒杀和抢购，是两个比较典型的互联网高并发场景。虽然我们解决问题的具体技术方案可能千差万别，但是遇到的挑战却是相似的，因此解决问题的思路也异曲同工。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;秒杀架构&quot;&gt;&lt;a href=&quot;#秒杀架构&quot; class=&quot;headerlink&quot; title=&quot;秒杀架构&quot;&gt;&lt;/a&gt;秒杀架构&lt;/h1&gt;&lt;h2 id=&quot;秒杀业务分析&quot;&gt;&lt;a href=&quot;#秒杀业务分析&quot; class=&quot;headerlink&quot; title=&quot;秒杀业务分
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>spring boot best pratices</title>
    <link href="http://yoursite.com/2018/07/04/SpringBoot%20Best%20Pratices/"/>
    <id>http://yoursite.com/2018/07/04/SpringBoot Best Pratices/</id>
    <published>2018-07-04T11:54:58.000Z</published>
    <updated>2019-06-12T11:57:10.858Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>Use Lombok to decoreate Java POJOs.<br><code>`</code><br>@Data<br>@Builder<br>public class Address {<br> @Id<br> private Long id;</p><p> private String city;<br>}</p></li></ol><p>//usage<br>Address address = Address.builder().city(“shenzhen”).build();<br><code>`</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;Use Lombok to decoreate Java POJOs.&lt;br&gt;&lt;code&gt;`&lt;/code&gt;&lt;br&gt;@Data&lt;br&gt;@Builder&lt;br&gt;public class Address {&lt;br&gt; @Id&lt;br&gt; private Long id
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>支付功能安全</title>
    <link href="http://yoursite.com/2018/05/02/%E6%94%AF%E4%BB%98%E5%8A%9F%E8%83%BD%E5%AE%89%E5%85%A8/"/>
    <id>http://yoursite.com/2018/05/02/支付功能安全/</id>
    <published>2018-05-02T14:08:42.000Z</published>
    <updated>2019-06-12T12:01:55.379Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>密钥信息不能泄漏</p></li><li><p>接口安全验证</p><ul><li>接口请求验证</li><li>数据返回加密</li></ul></li><li><p>服务器安全</p><ul><li>设置密码复杂度</li><li>关闭不必要的端口，开启防火墙</li><li>sudo权限限制</li><li>超级管理员权限</li><li>处理没有属主的文件</li><li>设置各服务权限</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;密钥信息不能泄漏&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;接口安全验证&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接口请求验证&lt;/li&gt;
&lt;li&gt;数据返回加密&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;服务器安全&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设置密码复杂度&lt;/li&gt;
&lt;li
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>三方登录</title>
    <link href="http://yoursite.com/2018/04/24/%E4%B8%89%E6%96%B9%E7%99%BB%E5%BD%95/"/>
    <id>http://yoursite.com/2018/04/24/三方登录/</id>
    <published>2018-04-24T13:33:43.000Z</published>
    <updated>2019-06-12T11:43:59.370Z</updated>
    
    <content type="html"><![CDATA[<h1 id="三方登录"><a href="#三方登录" class="headerlink" title="三方登录"></a>三方登录</h1><p>国内APP常用的第三方登录通常包括： 微信、QQ、微博</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>第三方登录流程一般是：</p><ol><li>前端（web, Android, iOS）先获取code</li><li>然后把code发送到后端，后端通过appId, appSecret获取access_token</li><li>后端再根据token获取第三方平台的用户信息</li><li>后面就是自己平台的用户与第三方平台用户的信息绑定逻辑了</li></ol><p>APP 微博、微信登录，回跳地址怎么回事？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;三方登录&quot;&gt;&lt;a href=&quot;#三方登录&quot; class=&quot;headerlink&quot; title=&quot;三方登录&quot;&gt;&lt;/a&gt;三方登录&lt;/h1&gt;&lt;p&gt;国内APP常用的第三方登录通常包括： 微信、QQ、微博&lt;/p&gt;
&lt;h2 id=&quot;流程&quot;&gt;&lt;a href=&quot;#流程&quot; clas
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Spring 事务</title>
    <link href="http://yoursite.com/2018/03/21/Spring%20%E4%BA%8B%E5%8A%A1/"/>
    <id>http://yoursite.com/2018/03/21/Spring 事务/</id>
    <published>2018-03-21T11:01:40.000Z</published>
    <updated>2019-06-12T11:43:59.370Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spring-事务"><a href="#Spring-事务" class="headerlink" title="Spring 事务"></a>Spring 事务</h1><h2 id="Propagation"><a href="#Propagation" class="headerlink" title="Propagation"></a>Propagation</h2><ol><li>PROPAGATION_REQUIRED(默认): 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是 最常见的选择。</li><li>PROPAGATION_SUPPORTS: 支持当前事务，如果当前没有事务，就以非事务方式执行。</li><li>PROPAGATION_MANDATORY: 使用当前的事务，如果当前没有事务，就抛出异常。</li><li>PROPAGATION_REQUIRES_NEW: 新建事务，如果当前存在事务，把当前事务挂起。</li><li>PROPAGATION_NOT_SUPPORTED： 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</li><li>PROPAGATION_NEVER： 以非事务方式执行，如果当前存在事务，则抛出异常。</li><li>PROPAGATION_NESTED： 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与 PROPAGATION_REQUIRED 类似的操作。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Spring-事务&quot;&gt;&lt;a href=&quot;#Spring-事务&quot; class=&quot;headerlink&quot; title=&quot;Spring 事务&quot;&gt;&lt;/a&gt;Spring 事务&lt;/h1&gt;&lt;h2 id=&quot;Propagation&quot;&gt;&lt;a href=&quot;#Propagation&quot; c
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>OutOfMemoryError 与 StackOverflowError</title>
    <link href="http://yoursite.com/2018/02/27/OutOfMemoryError%E5%BC%82%E5%B8%B8/"/>
    <id>http://yoursite.com/2018/02/27/OutOfMemoryError异常/</id>
    <published>2018-02-27T11:01:00.000Z</published>
    <updated>2019-06-12T11:43:59.323Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OutOfMemoryError-与-StackOverflowError"><a href="#OutOfMemoryError-与-StackOverflowError" class="headerlink" title="OutOfMemoryError 与 StackOverflowError"></a>OutOfMemoryError 与 StackOverflowError</h1><p>除了程序计数器外，虚拟机内存的其他几个运行时区域都有可能发生OutOfMemoryError异常。</p><h2 id="Java堆溢出"><a href="#Java堆溢出" class="headerlink" title="Java堆溢出"></a>Java堆溢出</h2><p>Java堆用于存储对象实例，只要不断地创建对象，并且没有被垃圾回收机制清除，在对象数量到达最大堆的容量限制后就会产生内存溢出异常。</p><p>异常信息提示“java.lang.OutOfMemoryError”, “Java heap space”。</p><p>通过内存映象分析工具（如Eclipse Memory Analyzor)对Dump出来的堆转储快照进行分析。</p><p>从代码上检查是否存在某些对象生命周期过长，持有状态时间过长的情况，尝试减少程序运行期的内存消耗。另外检查虚拟机的堆参数（-Xmx与-Xms），与机器物理内存对比看是否还可以调大。</p><h2 id="虚拟机栈和本地方法栈溢出"><a href="#虚拟机栈和本地方法栈溢出" class="headerlink" title="虚拟机栈和本地方法栈溢出"></a>虚拟机栈和本地方法栈溢出</h2><p>HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，因此对于HotSpot来说，栈容量只由-Xss参数设定。</p><p>这两区域有以下两种异常：</p><ul><li>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常;</li><li>如果虚拟机在扩展栈时，无法申请到足够的内存空间，则抛出OutOfMemroyError异常。</li></ul><p>单个线程下，无论是由于栈帧太大，还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是StackOverflowError异常。</p><p>多线程情况下，每个线程分配到的栈容量越大，可以建立的线程数量越少，建立越多线程更容易把内存耗尽。</p><p>因为操作系统分配给每个进程的内存是有限制的，譬如32位的Windows限制为2GB,虚拟机提供了参数来控制Java堆和方法区的这两部分内存的最大值。剩余的内存为2GB（操作系统限制）减去Xmx(最大堆容量),再减去MaxPermSize(最大方法区容量)，程序计数器消耗内存很小，可以忽略掉。如果虚拟机进程本身耗费的内存不计算在内，剩下的内存就由虚拟机栈和本地方法栈瓜分了。</p><p>解决方法： 如果是建立过多线程导致的内存溢出，在不能减少线程数量的情况下，就只能通过减最大堆和减少栈容量来换取更多的线程。</p><h2 id="方法区和运行时常量池溢出"><a href="#方法区和运行时常量池溢出" class="headerlink" title="方法区和运行时常量池溢出"></a>方法区和运行时常量池溢出</h2><p>运行时常量池是方法区的一部分。在JDK1.6及之前的版本中，由于常量池分配在永久代内，我们可以通过-XX:PermSize和-XX:MaxPermSize限制方法区大小，从而间接限制其中常量池的容量。</p><p>方法区用于存放Class的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。这些区域的测试，可以在运行时产生大量的类去填满方法区，直到溢出。</p><h2 id="本地直接内存溢出"><a href="#本地直接内存溢出" class="headerlink" title="本地直接内存溢出"></a>本地直接内存溢出</h2><p>DirectMemory容量可通过-XX:MaxDirectMemorySize指定，如果不指定，则默认与Java堆最大值（-Xmx指定）一样。</p><p>由DirectMemory导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见明显的异常，如果读者发现OOM之后Dump文件很小，而程序中又直接或间接使用了NIO, 可以考虑检查一下是不是这方面的原因。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;OutOfMemoryError-与-StackOverflowError&quot;&gt;&lt;a href=&quot;#OutOfMemoryError-与-StackOverflowError&quot; class=&quot;headerlink&quot; title=&quot;OutOfMemoryError 与
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch</title>
    <link href="http://yoursite.com/2018/02/12/ElasticSearch/"/>
    <id>http://yoursite.com/2018/02/12/ElasticSearch/</id>
    <published>2018-02-12T11:37:08.000Z</published>
    <updated>2019-06-12T11:54:19.853Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h1><p>Elasticsearch is a distributed, RESTful search and analytics engine capable of solving a growing number of use cases. As the heart of the Elastic Stack, it centrall stores your data so you can discover the expected and uncover the unexpected.<br>Elasticsearch是一个分布式的，RESTful搜索接口的，分析引擎，能够解决数据增长的安全。Elastic栈的核心是集中存储你的数据，所以你能够查找希望的，隐藏不想要的数据。</p><h2 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use-cases"></a>Use-cases</h2><ol><li>Search for products on online web store.</li><li>Collect log to analyze this data for statistics.</li><li>Use Elasticsearch aggreations functionality to perform complex business intelligence queries and use Kibana to build custom dashboards.</li></ol><h2 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h2><h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h3><p>A cluster is a collection of one or more nodes that together holds your entire data and provides federated indexing and search capabilities across all nodes.<br>一个集群是一个或多个节点的集合，这些节点一起组成你全部的数据，提供联合的索引，能够在全部节点搜索。</p><h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><p>A node is a sigle server that is part of your cluster, stores your data, and participates in the cluster’s indexing and search capabilities.<br>节点是你的集群中的一台服务器，存储你的数据，参与集群的索引与搜索。</p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><p>An index is a collection of documents that have somewhat similar characteristics. In a single cluster, you can define as many indexes as you want.<br>索引是某种程度有共同点的文档的集合。一个集群，你可以声明你想要的数量的索引。</p><h3 id="Type"><a href="#Type" class="headerlink" title="Type"></a>Type</h3><p>A type used to be a logical category/partition of your index to allow you to store different types of documents in the same index. It is no longer possible to create multiple types in an index, and the whole concept of types will be removed in a later version.<br>一种类型曾经是索引的逻辑目录/分区，允许你在同一个索引存储不同类型的文档。以后不再可能在一个索引中创建多个类型，后续的版本将会移除这整个概念。</p><h3 id="Document"><a href="#Document" class="headerlink" title="Document"></a>Document</h3><p>A document is a basic unit of information that can be indexed.<br>文档是索引的基础信息单元。</p><h3 id="Shards-amp-Replicas"><a href="#Shards-amp-Replicas" class="headerlink" title="Shards &amp; Replicas"></a>Shards &amp; Replicas</h3><p>Elasticsearch provides the ability to subdivide your index into multiple pieces called shards. Elasticsearch allows you to make one or more copies of your index’s shards into what are called replica shards, or replicas for short.<br>Elasticsearch可以把你的索引细分成多块，称为碎片。Elasticsearch允许你将索引分片的一个或多个副本制作成所谓的副本分片或简称副本。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Elasticsearch&quot;&gt;&lt;a href=&quot;#Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch&quot;&gt;&lt;/a&gt;Elasticsearch&lt;/h1&gt;&lt;p&gt;Elasticsearch is a distrib
      
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="ELK" scheme="http://yoursite.com/tags/ELK/"/>
    
  </entry>
  
</feed>
